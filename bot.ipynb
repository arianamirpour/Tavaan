{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import g4f \n",
    "# from g4f.Provider import ChatgptAi\n",
    "\n",
    "\n",
    "response = g4f.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"از چه ورژن هوش مصنوعی استفاده میکنی\"}],\n",
    "    # provider= ChatgptAi,\n",
    "    # cookies={\"_dd_s\": \"rum=0&expire=1701797880982\"},\n",
    "    # auth=True,\n",
    "    stream=True\n",
    "\n",
    ")\n",
    "\n",
    "for message in response:\n",
    "    print(message, flush= True, end='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from balethon import Client\n",
    "\n",
    "bot = Client(\"1158022023:GLsTHaMNLNLrLEi2PmYc5PhRV19ArO5vQuz7e9UT\")\n",
    "\n",
    "\n",
    "@bot.on_command(['start'])\n",
    "async def welcome(message):\n",
    "    await message.reply('Hey! This Chat Bot is using ChatGPT and was developed by kit4py. Enjoy!')\n",
    "\n",
    "client = OpenAI(\n",
    "# This is the default and can be omitted\n",
    " api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "@bot.on_message()\n",
    "async def gpt(message):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message.text,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "    await message.reply(chat_completion.choices[0].text)\n",
    "\n",
    "\n",
    "bot.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/arian/Downloads/Telegram GPT bot/bot.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arian/Downloads/Telegram%20GPT%20bot/bot.ipynb#W4sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arian/Downloads/Telegram%20GPT%20bot/bot.ipynb#W4sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     logging\u001b[39m.\u001b[39mbasicConfig(level\u001b[39m=\u001b[39mlogging\u001b[39m.\u001b[39mINFO, stream\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstdout)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arian/Downloads/Telegram%20GPT%20bot/bot.ipynb#W4sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     asyncio\u001b[39m.\u001b[39;49mrun(main())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug, loop_factory)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[39mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[39m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[39mwith\u001b[39;00m Runner(debug\u001b[39m=\u001b[39mdebug, loop_factory\u001b[39m=\u001b[39mloop_factory) \u001b[39mas\u001b[39;00m runner:\n\u001b[1;32m    194\u001b[0m     \u001b[39mreturn\u001b[39;00m runner\u001b[39m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import sys\n",
    "from os import getenv\n",
    "\n",
    "from aiogram import Bot, Dispatcher, Router, types\n",
    "from aiogram.enums import ParseMode\n",
    "from aiogram.filters import CommandStart\n",
    "from aiogram.types import Message\n",
    "from aiogram.utils.markdown import hbold\n",
    "\n",
    "# Bot token can be obtained via https://t.me/BotFather\n",
    "TOKEN = getenv(\"6695135667:AAF93rJDAp7Hdoig_gIQnYJK5sREx5jcMlU\")\n",
    "\n",
    "# All handlers should be attached to the Router (or Dispatcher)\n",
    "dp = Dispatcher()\n",
    "\n",
    "\n",
    "@dp.message(CommandStart())\n",
    "async def command_start_handler(message: Message) -> None:\n",
    "    \"\"\"\n",
    "    This handler receives messages with `/start` command\n",
    "    \"\"\"\n",
    "    # Most event objects have aliases for API methods that can be called in events' context\n",
    "    # For example if you want to answer to incoming message you can use `message.answer(...)` alias\n",
    "    # and the target chat will be passed to :ref:`aiogram.methods.send_message.SendMessage`\n",
    "    # method automatically or call API method directly via\n",
    "    # Bot instance: `bot.send_message(chat_id=message.chat.id, ...)`\n",
    "    await message.answer(f\"Hello, {hbold(message.from_user.full_name)}!\")\n",
    "\n",
    "\n",
    "@dp.message()\n",
    "async def echo_handler(message: types.Message) -> None:\n",
    "    \"\"\"\n",
    "    Handler will forward receive a message back to the sender\n",
    "\n",
    "    By default, message handler will handle all message types (like a text, photo, sticker etc.)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Send a copy of the received message\n",
    "        await message.send_copy(chat_id=message.chat.id)\n",
    "    except TypeError:\n",
    "        # But not all the types is supported to be copied so need to handle it\n",
    "        await message.answer(\"Nice try!\")\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    # Initialize Bot instance with a default parse mode which will be passed to all API calls\n",
    "    bot = Bot(TOKEN, parse_mode=ParseMode.HTML)\n",
    "    # And the run events dispatching\n",
    "    await dp.start_polling(bot)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
